{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"19jZ8dDxZjlk8cu5o5YrGqYN4HtK6Lnfu","authorship_tag":"ABX9TyNLuWMZydaMktF5gWCCUyhO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# versions\n","\n","v1 1,6,3,clicks_th=20,carts_th=15,orders_th=15\n","\n","v2 0.5,9,0.5,clicks_th=15,carts_th=20,orders_th=20\n","\n","v3 1,6,3,clicks_th=30,carts_th=30,orders_th=30\n","\n","v4 1,6,3,clicks_th=40,carts_th=40,orders_th=40\n","\n","v5 1,6,3,clicks_th=50,carts_th=50,orders_th=50\n","\n","v6 1,6,3,clicks_th=20,carts_th=15,orders_th=15,drop"],"metadata":{"id":"EDCdOPxS5Mag"}},{"cell_type":"markdown","source":["# setting"],"metadata":{"id":"TJr3elUQURJz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"DpMC1odzdvxr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675042947126,"user_tz":-540,"elapsed":19103,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"f2fb68ea-1434-4159-fc0f-ab626465afb9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["type_weight = {0:1,\n","               1:6,\n","               2:3}\n","clicks_th = 20 # クリック数\n","carts_th  = 15 # カート数\n","orders_th = 15 # 購入数\n","\n","VER = 6"],"metadata":{"id":"BJpmUXs8TcS_","executionInfo":{"status":"ok","timestamp":1675042947127,"user_tz":-540,"elapsed":6,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKRQJddKSZzk","executionInfo":{"status":"ok","timestamp":1675042948122,"user_tz":-540,"elapsed":1000,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"dfd01251-50d7-4580-9b62-1c497310104e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jan 30 01:42:26 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!pip install -q cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n","import pandas as pd\n","import numpy as np\n","import os,sys,pickle,glob,gc\n","from collections import Counter\n","import cudf,itertools\n","pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 100)\n","print('We will use RAPIDS version',cudf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iEFxaP7SkeY","executionInfo":{"status":"ok","timestamp":1675042979049,"user_tz":-540,"elapsed":30931,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"db846bfe-b075-43ac-c218-af4325b9ffb1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.6/453.6 KB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m923.4/923.4 KB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n","tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mWe will use RAPIDS version 22.12.0\n"]}]},{"cell_type":"code","source":["%%time\n","# CACHE FUNCTIONS\n","def read_file(f):\n","    return cudf.DataFrame( data_cache[f] )\n","def read_file_to_cache(f):\n","    df = pd.read_parquet(f)\n","    df.ts = (df.ts/1000).astype('int32')\n","    df['type'] = df['type'].map(type_labels).astype('int8')\n","    return df\n","\n","# CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n","data_cache = {}\n","type_labels = {'clicks':0, 'carts':1, 'orders':2}\n","files = glob.glob('/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/original/*_parquet/*')\n","for f in files: data_cache[f] = read_file_to_cache(f)\n","\n","# CHUNK PARAMETERS\n","READ_CT = 5\n","CHUNK = int( np.ceil( len(files)/6 ))\n","print(f'We will process {len(files)} files, in groups of {READ_CT} and chunks of {CHUNK}.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSG1xFjrSrj1","executionInfo":{"status":"ok","timestamp":1675043060388,"user_tz":-540,"elapsed":81344,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"3357c0d3-75fa-4b79-8f47-a1324302ef83"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["We will process 146 files, in groups of 5 and chunks of 25.\n","CPU times: user 33.8 s, sys: 9.04 s, total: 42.8 s\n","Wall time: 1min 21s\n"]}]},{"cell_type":"code","source":["%%time\n","\n","\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 4\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min( (j+1)*CHUNK, len(files) )\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i<b: df.append( read_file(files[k+i]) )\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = df.type_y.map(type_weight)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 40\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n<carts_th].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/co-visitation matrix/test/top_15_carts_orders_v{VER}_{PART}.pqt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YfGu17XGSvn0","executionInfo":{"status":"ok","timestamp":1675043146693,"user_tz":-540,"elapsed":86325,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"0b580982-6a11-4158-9742-ea976bd40783"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 2\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 3\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 4\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 46.8 s, sys: 12.8 s, total: 59.6 s\n","Wall time: 1min 26s\n"]}]},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 1\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min( (j+1)*CHUNK, len(files) )\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i<b: df.append( read_file(files[k+i]) )\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y) ] # 14 DAYS\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = 1\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 40\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n<orders_th].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/co-visitation matrix/test/top_15_buy2buy_v{VER}_{PART}.pqt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3zQ_oRzS_qj","executionInfo":{"status":"ok","timestamp":1675043159697,"user_tz":-540,"elapsed":13024,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"1312d402-1b6d-485f-f65d-39114e809858"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 9.36 s, sys: 2.17 s, total: 11.5 s\n","Wall time: 13.2 s\n"]}]},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 4\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min( (j+1)*CHUNK, len(files) )\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i<b: df.append( read_file(files[k+i]) )\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n","            df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 40\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n<clicks_th].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/co-visitation matrix/test/top_20_clicks_v{VER}_{PART}.pqt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hytmXY2iZvjP","executionInfo":{"status":"ok","timestamp":1675043242539,"user_tz":-540,"elapsed":82861,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"68241388-63d7-49d2-8c4e-045043ebaf2a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 2\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 3\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","\n","### DISK PART 4\n","Processing files 0 thru 24 in groups of 5...\n","0 , 5 , 10 , 15 , 20 , \n","Processing files 25 thru 49 in groups of 5...\n","25 , 30 , 35 , 40 , 45 , \n","Processing files 50 thru 74 in groups of 5...\n","50 , 55 , 60 , 65 , 70 , \n","Processing files 75 thru 99 in groups of 5...\n","75 , 80 , 85 , 90 , 95 , \n","Processing files 100 thru 124 in groups of 5...\n","100 , 105 , 110 , 115 , 120 , \n","Processing files 125 thru 145 in groups of 5...\n","125 , 130 , 135 , 140 , 145 , \n","CPU times: user 45.5 s, sys: 11.8 s, total: 57.3 s\n","Wall time: 1min 22s\n"]}]},{"cell_type":"code","source":["%%time\n","# CACHE FUNCTIONS\n","def read_file(f):\n","    return cudf.DataFrame( data_cache[f] )\n","def read_file_to_cache(f):\n","    df = pd.read_parquet(f)\n","    df.ts = (df.ts/1000).astype('int32')\n","    df['type'] = df['type'].map(type_labels).astype('int8')\n","    return df\n","\n","# CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n","data_cache = {}\n","type_labels = {'clicks':0, 'carts':1, 'orders':2}\n","files = glob.glob('/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/otto-validation/*_parquet/*')\n","for f in files: data_cache[f] = read_file_to_cache(f)\n","\n","# CHUNK PARAMETERS\n","READ_CT = 5\n","CHUNK = int( np.ceil( len(files)/6 ))\n","print(f'We will process {len(files)} files, in groups of {READ_CT} and chunks of {CHUNK}.')"],"metadata":{"id":"mokpJX2x7nVp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675043317771,"user_tz":-540,"elapsed":75235,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"04629884-b517-47f3-9dd2-9bea20005ad4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["We will process 120 files, in groups of 5 and chunks of 20.\n","CPU times: user 23 s, sys: 4.91 s, total: 27.9 s\n","Wall time: 1min 14s\n"]}]},{"cell_type":"code","source":["%%time\n","\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 4\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min( (j+1)*CHUNK, len(files) )\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i<b: df.append( read_file(files[k+i]) )\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = df.type_y.map(type_weight)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 40\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n<carts_th].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/co-visitation matrix/val/top_15_carts_orders_v{VER}_{PART}.pqt')"],"metadata":{"id":"b5-j5-bJ7nTT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675043371281,"user_tz":-540,"elapsed":53514,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"2eb97ff3-1b11-4816-f9c0-72dce16acf0d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","\n","### DISK PART 2\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","\n","### DISK PART 3\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","\n","### DISK PART 4\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","CPU times: user 31.5 s, sys: 8.35 s, total: 39.8 s\n","Wall time: 53.7 s\n"]}]},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 1\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min( (j+1)*CHUNK, len(files) )\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i<b: df.append( read_file(files[k+i]) )\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y) ] # 14 DAYS\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n","            df['wgt'] = 1\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 40\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n<orders_th].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/co-visitation matrix/val/top_15_buy2buy_v{VER}_{PART}.pqt')"],"metadata":{"id":"mIkl7heW7nQc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675043380204,"user_tz":-540,"elapsed":8942,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"e6647dfc-ecb3-4994-d93f-62d6852edfed"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","CPU times: user 6.01 s, sys: 1.47 s, total: 7.48 s\n","Wall time: 8.89 s\n"]}]},{"cell_type":"code","source":["%%time\n","# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n","DISK_PIECES = 4\n","SIZE = 1.86e6/DISK_PIECES\n","\n","# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n","for PART in range(DISK_PIECES):\n","    print()\n","    print('### DISK PART',PART+1)\n","    \n","    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n","    # => OUTER CHUNKS\n","    for j in range(6):\n","        a = j*CHUNK\n","        b = min( (j+1)*CHUNK, len(files) )\n","        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n","        \n","        # => INNER CHUNKS\n","        for k in range(a,b,READ_CT):\n","            # READ FILE\n","            df = [read_file(files[k])]\n","            for i in range(1,READ_CT): \n","                if k+i<b: df.append( read_file(files[k+i]) )\n","            df = cudf.concat(df,ignore_index=True,axis=0)\n","            df = df.sort_values(['session','ts'],ascending=[True,False])\n","            # USE TAIL OF SESSION\n","            df = df.reset_index(drop=True)\n","            df['n'] = df.groupby('session').cumcount()\n","            df = df.loc[df.n<30].drop('n',axis=1)\n","            # CREATE PAIRS\n","            df = df.merge(df,on='session')\n","            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n","            # MEMORY MANAGEMENT COMPUTE IN PARTS\n","            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n","            # ASSIGN WEIGHTS\n","            df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n","            df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n","            df = df[['aid_x','aid_y','wgt']]\n","            df.wgt = df.wgt.astype('float32')\n","            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n","            # COMBINE INNER CHUNKS\n","            if k==a: tmp2 = df\n","            else: tmp2 = tmp2.add(df, fill_value=0)\n","            print(k,', ',end='')\n","        print()\n","        # COMBINE OUTER CHUNKS\n","        if a==0: tmp = tmp2\n","        else: tmp = tmp.add(tmp2, fill_value=0)\n","        del tmp2, df\n","        gc.collect()\n","    # CONVERT MATRIX TO DICTIONARY\n","    tmp = tmp.reset_index()\n","    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n","    # SAVE TOP 40\n","    tmp = tmp.reset_index(drop=True)\n","    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n","    tmp = tmp.loc[tmp.n<clicks_th].drop('n',axis=1)\n","    # SAVE PART TO DISK (convert to pandas first uses less memory)\n","    tmp.to_pandas().to_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/co-visitation matrix/val/top_20_clicks_v{VER}_{PART}.pqt')"],"metadata":{"id":"Frl8jksP7nNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675043433125,"user_tz":-540,"elapsed":52929,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"3e41eb6c-efd5-4a00-d9e2-bc3fd928bd5b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","### DISK PART 1\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","\n","### DISK PART 2\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","\n","### DISK PART 3\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","\n","### DISK PART 4\n","Processing files 0 thru 19 in groups of 5...\n","0 , 5 , 10 , 15 , \n","Processing files 20 thru 39 in groups of 5...\n","20 , 25 , 30 , 35 , \n","Processing files 40 thru 59 in groups of 5...\n","40 , 45 , 50 , 55 , \n","Processing files 60 thru 79 in groups of 5...\n","60 , 65 , 70 , 75 , \n","Processing files 80 thru 99 in groups of 5...\n","80 , 85 , 90 , 95 , \n","Processing files 100 thru 119 in groups of 5...\n","100 , 105 , 110 , 115 , \n","CPU times: user 30.7 s, sys: 8.24 s, total: 39 s\n","Wall time: 52.9 s\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jjBFZ4sJ7nFL","executionInfo":{"status":"ok","timestamp":1675043433126,"user_tz":-540,"elapsed":7,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":12,"outputs":[]}]}