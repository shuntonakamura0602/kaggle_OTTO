{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["wR79WCjinP1T","2Rf79lVhnk3I","zb729Xndorzo","ldp8OLDTpP0A","qjvmeN6IpZGb","MfLla9P3qFAg","KnjluHTGqwuq","59NGCGVtrFWh","ehOyBx2du33z","KNPQ0MAlvlWD","KHbt2LSCv7ng","gVHHAinEwj4_"],"machine_shape":"hm","authorship_tag":"ABX9TyMjoHpY6HQ+WzXYL/DYxU4f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# GBTランカーモデルの作り方\n","\n","一般的な考え方は、各セッション（つまりユーザー）に対して、50～200の候補（正しい予測である可能性が高い）を見つけ、GBTランカーモデルを学習して最終的に20を選択する、というものです。\n","\n","そのためには、ランカーモデル用の学習データを作成する必要があります。"],"metadata":{"id":"wR79WCjinP1T"}},{"cell_type":"markdown","source":["# 候補者データフレーム\n","\n","ランカーモデルの学習データを作成するための最初のステップは、候補のデータフレームを作成することです。\n","\n","高品質な候補を生成する一つの方法として、co-visitiation matricesを使用する方法があります。\n","\n","候補データフレームは、1行に1組のセッション（＝ユーザ）とエイド（＝アイテム）を持ちます。このデータフレームは以下の列を持ちます。\n","\n","* session (i.e. user)\n","* aid (i.e. item)\n","* user features\n","* item features\n","* user-item interaction features\n","* click target (i.e 0 or 1)\n","* cart target (i.e. 0 or 1)\n","* order target (i.e. 0 or 1)"],"metadata":{"id":"2Rf79lVhnk3I"}},{"cell_type":"markdown","source":["# メモリ管理\n","\n","最新バージョンのcuDF（バージョン22.08以降）をローカルで使用する場合、デフォルトのビット幅を32に設定する新しい機能があります。\n","\n","これにより、データフレームがint64やfloat64を使用することがなくなり、使い勝手が良くなります。\n","```\n","import cudf\n","\n","cudf.set_option(\"default_integer_bitwidth\", 32)\n","\n","cudf.set_option(\"default_float_bitwidth\", 32)\n","```\n","カラムのdtypesを減らしても、メモリに問題がある場合があります。\n","\n","これを解決する方法は、すべてをチャンクに分割して処理することです。\n","\n","train.groupby('session')を用いてユーザ特徴量を作成する場合、まず、訓練データをX個（2、4、8個など）に分割することが考えられます。\n","\n","そして、各個別にユーザ特徴量を処理し、f'user_features_p{PIECE_NUMBER}.pqt'としてディスクに保存してください。\n","\n","後で読み込むときに、それらを連結することができます。\n"],"metadata":{"id":"zb729Xndorzo"}},{"cell_type":"markdown","source":["# スピード - GPUの使用\n","\n","このデータには約1300万人のユーザーと200万点のアイテムがあるため、以下のコードは全て実行に時間がかかるでしょう。\n","\n","以下の処理には、NvidiaのRAPIDS cuDFのように、CPUの代わりにGPUを使用して高速化されたデータフレームライブラリを使用することをお勧めします。"],"metadata":{"id":"ldp8OLDTpP0A"}},{"cell_type":"markdown","source":["# ステップ1\n","\n","トレーニングデータは、Kaggleトレーニングの最初の3週間分のデータを使用します。\n","\n","そして、検証データはKaggle trainの最後の1週間分とします。\n","\n","\n","検証データA（つまりKaggle trainの最後の1週間）のすべてのユーザー（つまりセッション）に対して、X個の候補aidを生成します。\n","\n","ここでは、X=50とする。ここで、(number_of_session x 50, 2 )という形状のデータフレームを作成します。\n","\n","各セッションは50回ずつ登場します。\n","\n","また、[session,aid]のペアが重複することはないでしょう。\n","\n","検証データのユーザーしかターゲットにしないので、検証データのユーザーしか使いません（以下のステップ6で）。"],"metadata":{"id":"qjvmeN6IpZGb"}},{"cell_type":"markdown","source":["# ステップ2\n","\n","アイテム特徴を作成する。\n","\n","訓練データ＋検証データA（テストリークを使用）を用いて、項目特徴を独自のデータフレームで作成し、ディスクにパーケットを保存します。\n","\n","例えば\n","```\n","item_features = train.groupby('aid').agg({'aid':'count','session':'nunique','type':'mean'})\n","\n","item_features.columns = ['item_item_count','item_user_count','item_buy_ratio']\n","\n","CONVERT COLUMNS TO INT32 and FLOAT32 HERE\n","item_features.to_parquet('item_features.pqt')\n","```\n","メモリに問題がある場合はご注意ください。\n","\n","train を 10 個の dataframe part に分割する．\n","\n","train_part_1.groupby('aid') が正しく動作するように、1つの項目に関連するすべての行は、同じデータフレーム部分でなければなりません。\n","\n","処理後、各パートを別々にディスクに保存する。そして、後でディスクから読み込む際に、候補データフレームにマージする前に、それらを連結する。"],"metadata":{"id":"MfLla9P3qFAg"}},{"cell_type":"markdown","source":["# ステップ3\n","\n","ユーザー特徴量の作成 \n","\n","検証データAを用いて、ユーザー特徴を独自のデータフレームに作成し、ディスクにパーケットを保存します。\n","\n","例えば\n","\n","```\n","user_features = train.groupby('session').agg({'session':'count','aid':'nunique','type':'mean'})\n","user_features.columns = ['user_user_count','user_item_count','user_buy_ratio']\n","CONVERT COLUMNS TO INT32 and FLOAT32 HERE\n","user_features.to_parquet('user_features.pqt')\n","```"],"metadata":{"id":"KnjluHTGqwuq"}},{"cell_type":"markdown","source":["# ステップ4\n","\n","このステップはオプションです。\n","\n","ステップ4はCVとLBを改善しますが、GBTランカーはステップ4なしでも動作します。\n","\n","ユーザーアイテムインタラクション特徴量の作成 \n","\n","検証データAを用いて、複数のユーザーアイテム特徴量データフレームを作成し、ディスクにパーケットとして保存する。\n","\n","各アイデアに対して、新しいデータフレームを作成することができる。\n","\n","1つのデータフレームには、ユーザがクリックしたすべての項目を格納することができます。\n","\n","そこで、1列user、1列item、3列目item_clickedを持つデータフレームを作成します。\n","\n","そして、ユーザがクリックしたユニークなアイテムごとに、item_clicked = 1の新しい行を追加します。このデータフレームには、['user','item']のペアの重複行がないことに注意してください。\n","\n","このデータフレームをディスクに保存します。これを候補データフレームにマージする際には、クリックされなかった項目を示すために、fillna(0)を使用します。"],"metadata":{"id":"59NGCGVtrFWh"}},{"cell_type":"markdown","source":["# ステップ5\n","\n","候補データフレームに特徴量を追加する。\n","\n","候補データフレームに特徴を追加するために、以下のようにディスクから読み込んでマージします。\n","\n","\n","\n","```\n","item_features = pd.read_parquet('item_features.pqt')\n","candidates = candidates.merge(item_features, left_on='aid', right_index=True, how='left').fillna(-1)\n","user_features = pd.read_parquet('user_features.pqt')\n","candidates = candidates.merge(user_features, left_on='session', right_index=True, how='left').fillna(-1)\n","```\n","\n","注：もしすべての特徴を候補データフレームにマージする際にメモリに問題がある場合は、これを分割して行うことができます。\n","\n","```\n","CHUNKS = 10\n","chunk_size = np.ceil( len(candidates) / CHUNKS)\n","for k in range(CHUNKS):\n","    df = candidates.iloc[k*chunk_size:(k+1)*chunk_size].copy()\n","    df = df.merge(item_features, left_on='aid', right_index=True, how='left').fillna(-1)\n","    df = df.merge(user_features, left_on='session', right_index=True, how='left').fillna(-1)\n","    df.to_parquet(f'candidate_with_features_p{k}.pqt')\n","```\n","\n"],"metadata":{"id":"ehOyBx2du33z"}},{"cell_type":"markdown","source":["# ステップ6\n","\n","ステップ1で作成した候補データフレームにターゲットを追加します。\n","\n","targetの列を追加する最も良い方法は、dataframe mergeを使用することです。\n","\n","まず、以下のようにすべてのtarget=1のdataframeを作成します。\n","\n","以下のようなリストの列としてターゲットを含むdataframeからスタートします（ここではRadekのground truth labelsのように）。\n","\n","```\n","tar = pd.read_parquet('test_labels.parquet')\n","tar = tar.loc[ tar['type']=='carts' ]\n","aids = tar.ground_truth.explode().astype('int32').rename('item')\n","tar = tar[['session']].astype('int32').rename({'session':'user'},axis=1)\n","tar = tar.merge(aids, left_index=True, right_index=True, how='left')\n","tar['cart'] = 1\n","```"],"metadata":{"id":"KNPQ0MAlvlWD"}},{"cell_type":"markdown","source":["# トレーニング\n","\n","GBT ランカーモデル用の学習データができました。\n","\n","GroupKFoldを使って学習する必要があります。\n","\n","重要：学習時には、user と item のカラムは特徴量として使用せず、他のカラムのみを使用します。\n","```\n","FEATURES = candidates.columns[2 : -1*len(targets)]\n","```\n"," とします。XGBでは、objectiveパラメータを変更することで、rank:pairwise, rank:ndcg, rank:mapの3種類のランカーを選択することができることに注意してください。(XGBのパラメータ 'max_depth', 'subsample', 'colsample_bytree', 'learning_rate' も追加して調整する必要があります）。\n","\n","```\n","import xgboost as xgb\n","from sklearn.model_selection import GroupKFold\n","\n","skf = GroupKFold(n_splits=5)\n","for fold,(train_idx, valid_idx) in enumerate(skf.split(candidates, candidates['click'], groups=candidates['user'] )):\n","\n","    X_train = candidates.loc[train_idx, FEATURES]\n","    y_train = candidates.loc[train_idx, 'click']\n","    X_valid = candidates.loc[valid_idx, FEATURES]\n","    y_valid = candidates.loc[valid_idx, 'click']\n","\n","    # IF YOU HAVE 50 CANDIDATE WE USE 50 BELOW\n","    dtrain = xgb.DMatrix(X_train, y_train, group=[50] * (len(train_idx)//50) ) \n","    dvalid = xgb.DMatrix(X_valid, y_valid, group=[50] * (len(valid_idx)//50) ) \n","\n","    xgb_parms = {'objective':'rank:pairwise', 'tree_method':'gpu_hist'}\n","    model = xgb.train(xgb_parms, \n","        dtrain=dtrain,\n","        evals=[(dtrain,'train'),(dvalid,'valid')],\n","        num_boost_round=1000,\n","        verbose_eval=100)\n","    model.save_model(f'XGB_fold{fold}_click.xgb')\n","```\n","\n","注: GPU で XGB をトレーニングする際にメモリに問題がある場 合、frac = 0.5, 0.25, 0.1, または 0.05 でネガティブを 2x, 4x, 10x, 20x にダウンサンプ リングすることを検討してください（その後 DMatrix でグループサイズを 更新してください）。または、複数の GPU で DASK XGB を使用します。以下はコード例です。\n","\n","```\n","positives = candidates.loc[candidates['click']==1]\n","negatives = candidates.loc[candidates['click']==0].sample(frac=0.5)\n","candidates = pd.concat([positives,negatives],axis=0,ignore_index=True)\n","```"],"metadata":{"id":"KHbt2LSCv7ng"}},{"cell_type":"markdown","source":["# 推論\n","推論では、Kaggleのテストデータから新しい候補データフレームを作成します（以前の候補生成のテクニックを使用）。\n","\n","そして、4週間分のKaggle trainと1週間分のKaggle testからitemの特徴量を作成します。\n","\n","そして、Kaggleのテストデータからユーザー特徴を作成します。\n","\n","これらの特徴量を候補にマージします。そして、保存されたモデルを使って、クリックの予測を推測します。\n","\n","最後に、予測結果をソートして、20個を選びます。\n","```\n","preds = np.zeros(len(test_candidates))\n","for fold in range(5):\n","    model = xgb.Booster()\n","    model.load_model(f'XGB_fold{fold}_click.xgb')\n","    model.set_param({'predictor': 'gpu_predictor'})\n","    dtest = xgb.DMatrix(data=test_candidates[FEATURES])\n","    preds += model.predict(dtest)/5\n","predictions = test_candidates[['user','item']].copy()\n","predictions['pred'] = preds\n","\n","predictions = predictions.sort_values(['user','pred'], ascending=[True,False]).reset_index(drop=True)\n","predictions['n'] = predictions.groupby('user').item.cumcount().astype('int8')\n","predictions = predictions.loc[predictions.n<20]\n","sub = predictions.groupby('user').item.apply(list)\n","sub = sub.to_frame().reset_index()\n","sub.item = sub.item.apply(lambda x: \" \".join(map(str,x)))\n","sub.columns = ['session_type','labels']\n","sub.session_type = sub.session_type.astype('str')+ '_clicks'\n","```\n","\n","メモリエラーが発生した場合の注意 テストデータの1/10をロードすることを検討してください。\n","\n","その後、特徴をマージする。次に推論を行う。\n","\n","次の1/10をロードし、特徴量をマージし、推論を行う。最後に予測結果を連結してsubmission.csvを作る"],"metadata":{"id":"gVHHAinEwj4_"}},{"cell_type":"markdown","source":["# validation"],"metadata":{"id":"mN6mZsF_CniH"}},{"cell_type":"code","source":["VER = 1\n","FEATURES = [\n","        'user', 'item_item_count', 'item_user_count', \n","        'item_buy_ratio', 'user_user_count', 'user_item_count',\n","        'user_buy_ratio']"],"metadata":{"id":"tccCIyvgCt5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1FcuFyf0kps","executionInfo":{"status":"ok","timestamp":1674482584746,"user_tz":-540,"elapsed":1209,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"07e80f3e-d8c4-4b38-ffcf-49d3ec1c29b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jan 23 14:03:04 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4cQfs0pkwFg","executionInfo":{"status":"ok","timestamp":1674482599177,"user_tz":-540,"elapsed":14439,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"62b46088-15f1-44f0-f5bf-fb8dfe3d075b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd, numpy as np\n","import pickle, glob, gc\n","\n","from collections import Counter\n","import itertools\n","# multiprocessing \n","import psutil\n","from multiprocessing import Pool\n","from sklearn.model_selection import GroupKFold\n","import psutil\n","N_CORES = psutil.cpu_count()     # Available CPU cores\n","print(f\"N Cores : {N_CORES}\")\n","from multiprocessing import Pool"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JewV2ba6m4rV","executionInfo":{"status":"ok","timestamp":1674482600116,"user_tz":-540,"elapsed":948,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"5babcbdb-0b3a-4b77-8b27-e78fde0b1d31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["N Cores : 12\n"]}]},{"cell_type":"code","source":["def merge_candidate(SVER,IVER,UVER,TYPE,MODE):\n","    candidates = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/candidate/suggest/{TYPE}/{MODE}_{TYPE}{SVER}.pqt')\n","    candidates['session'] = candidates.index\n","    candidates = candidates.set_index('session')\n","    item_features = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/candidate/item/{MODE}_item{IVER}.pqt')\n","    candidates = candidates.merge(item_features, left_on='item', right_index=True, how='left').fillna(-1)\n","    user_features = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/candidate/user/{MODE}_user{UVER}.pqt')\n","    candidates = candidates.merge(user_features, left_on='session', right_index=True, how='left').fillna(-1)\n","    candidates['user'] = candidates.index\n","    candidates = candidates.set_index('user')\n","    return candidates"],"metadata":{"id":"pO7TL1NdpE2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def merge_target(TYPE,candidates):\n","    tar = pd.read_parquet('/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/otto-validation/test_labels.parquet')\n","    tar = tar.loc[ tar['type']==TYPE ]\n","    aids = tar.ground_truth.explode().astype('int32').rename('item')\n","    tar = tar[['session']].astype('int32').rename({'session':'user'},axis=1)\n","    tar = tar.merge(aids, left_index=True, right_index=True, how='left')\n","    tar[TYPE] = 1\n","    candidates = candidates.merge(tar,on=['user','item'],how='left').fillna(0)\n","    return candidates"],"metadata":{"id":"i308HpKvu27u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q xgboost==1.6.2\n","import xgboost as xgb\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import recall_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEg5Uz_rn9pa","executionInfo":{"status":"ok","timestamp":1674482612640,"user_tz":-540,"elapsed":12532,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"81194eaf-9455-41d8-c445-9d22d0a1ea86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["def train_xgb(candidates,TARGET):\n","    preds = np.zeros(len(candidates))\n","    skf = GroupKFold(n_splits=5)\n","    for fold,(train_idx, valid_idx) in enumerate(skf.split(candidates, candidates[TARGET], groups=candidates['user'] )):\n","\n","        X_train = candidates.loc[train_idx, FEATURES]\n","        y_train = candidates.loc[train_idx, TARGET]\n","        X_valid = candidates.loc[valid_idx, FEATURES]\n","        y_valid = candidates.loc[valid_idx, TARGET]\n","\n","        X_train = X_train.sort_values(\"user\").reset_index(drop=True)\n","        X_valid = X_valid.sort_values(\"user\").reset_index(drop=True)\n","\n","        train_group = X_train.groupby('user').user.agg('count').values\n","        valid_group = X_valid.groupby('user').user.agg('count').values\n","\n","        X_train = X_train.drop([\"user\"], axis=1)\n","        X_valid = X_valid.drop([\"user\"], axis=1)\n","\n","        dtrain = xgb.DMatrix(X_train, y_train,group=train_group)\n","        dvalid = xgb.DMatrix(X_valid, y_valid,group=valid_group)\n","\n","        xgb_parms = {\n","            'objective':'rank:pairwise', \n","            'tree_method':'gpu_hist',\n","            'random_state': 42, \n","            'learning_rate': 0.1,\n","            \"colsample_bytree\": 0.8, \n","            'max_depth': 6,\n","        }\n","        model = xgb.train(xgb_parms, \n","            dtrain=dtrain,\n","            evals=[(dtrain,'train'),(dvalid,'valid')],\n","            num_boost_round=1000,\n","            verbose_eval=500)\n","        preds[valid_idx] = model.predict(dvalid)\n","        model.save_model(f'XGB_fold{fold}_{TARGET}.xgb')\n","    predictions = candidates[['user','item']].copy()\n","    predictions['pred'] = preds\n","    predictions = predictions.sort_values(['user','pred'], ascending=[True,False]).reset_index(drop=True)\n","    predictions['n'] = predictions.groupby('user').item.cumcount().astype('int8')\n","    predictions = predictions.loc[predictions.n<20]\n","    sub = predictions.groupby('user').item.apply(list)\n","    sub = sub.to_frame().reset_index()\n","    sub.item = sub.item.apply(lambda x: \" \".join(map(str,x)))\n","    sub.columns = ['session','labels']\n","    sub.labels = sub.labels.apply(lambda x: [int(i) for i in x.split(' ')[:20]])\n","    test_labels = pd.read_parquet('/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/otto-validation/test_labels.parquet')\n","    test_labels = test_labels.loc[test_labels['type']==TARGET]\n","    test_labels = test_labels.merge(sub, how='left', on=['session'])\n","    test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n","    test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n","    recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n","    print('{} Recall = {:.5f}'.format(TARGET,recall))"],"metadata":{"id":"6umxdz4Ixy0k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## clicks"],"metadata":{"id":"pGaBc3vaC1p2"}},{"cell_type":"code","source":["%%time\n","candidates = merge_candidate(VER,'clicks','val')\n","candidates = merge_target('clicks',candidates)\n","train_xgb(candidates,'clicks')\n","del candidates\n","_ = gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oT_jz92-p01m","executionInfo":{"status":"ok","timestamp":1674483367094,"user_tz":-540,"elapsed":552324,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"80d10fd3-02fa-431d-e46f-572495aa3102"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0]\ttrain-map:0.65015\tvalid-map:0.64898\n","[500]\ttrain-map:0.59663\tvalid-map:0.59213\n","[999]\ttrain-map:0.59999\tvalid-map:0.59269\n","[0]\ttrain-map:0.65552\tvalid-map:0.65602\n","[500]\ttrain-map:0.59669\tvalid-map:0.59167\n","[999]\ttrain-map:0.60006\tvalid-map:0.59251\n","[0]\ttrain-map:0.66121\tvalid-map:0.65993\n","[500]\ttrain-map:0.59723\tvalid-map:0.59186\n","[999]\ttrain-map:0.60055\tvalid-map:0.59253\n","[0]\ttrain-map:0.66388\tvalid-map:0.66355\n","[500]\ttrain-map:0.59709\tvalid-map:0.59281\n","[999]\ttrain-map:0.60027\tvalid-map:0.59334\n","[0]\ttrain-map:0.66999\tvalid-map:0.66960\n","[500]\ttrain-map:0.59716\tvalid-map:0.59261\n","[999]\ttrain-map:0.60065\tvalid-map:0.59303\n","clicks Recall = 0.52558\n"]}]},{"cell_type":"markdown","source":["## carts"],"metadata":{"id":"xwNhJSGlC3k9"}},{"cell_type":"code","source":["%%time\n","candidates = merge_candidate(VER,'carts','val')\n","candidates = merge_target('carts',candidates)\n","train_xgb(candidates,'carts')\n","del candidates\n","_ = gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDXQIyuiBO04","executionInfo":{"status":"ok","timestamp":1674484794548,"user_tz":-540,"elapsed":513714,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"cd560f68-a9c9-4bc1-bd9c-2cadc0d78250"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0]\ttrain-map:0.91989\tvalid-map:0.91948\n","[500]\ttrain-map:0.91648\tvalid-map:0.91404\n","[999]\ttrain-map:0.91749\tvalid-map:0.91403\n","[0]\ttrain-map:0.92038\tvalid-map:0.91995\n","[500]\ttrain-map:0.91635\tvalid-map:0.91371\n","[999]\ttrain-map:0.91745\tvalid-map:0.91364\n","[0]\ttrain-map:0.92242\tvalid-map:0.92168\n","[500]\ttrain-map:0.91662\tvalid-map:0.91316\n","[999]\ttrain-map:0.91758\tvalid-map:0.91312\n","[0]\ttrain-map:0.92305\tvalid-map:0.92282\n","[500]\ttrain-map:0.91646\tvalid-map:0.91412\n","[999]\ttrain-map:0.91754\tvalid-map:0.91424\n","[0]\ttrain-map:0.92204\tvalid-map:0.92258\n","[500]\ttrain-map:0.91624\tvalid-map:0.91479\n","[999]\ttrain-map:0.91726\tvalid-map:0.91487\n","carts Recall = 0.40965\n"]}]},{"cell_type":"markdown","source":["## orders"],"metadata":{"id":"CqVLzUS_Di7w"}},{"cell_type":"code","source":["%%time\n","candidates = merge_candidate(VER,'orders','val')\n","candidates = merge_target('orders',candidates)\n","train_xgb(candidates,'orders')\n","del candidates\n","_ = gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY2mIQ-CGV8p","executionInfo":{"status":"ok","timestamp":1674485302273,"user_tz":-540,"elapsed":507742,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"cd8f9dcd-dfb0-411f-ed99-93cd3a25d8fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0]\ttrain-map:0.95522\tvalid-map:0.95512\n","[500]\ttrain-map:0.94850\tvalid-map:0.94647\n","[999]\ttrain-map:0.94950\tvalid-map:0.94647\n","[0]\ttrain-map:0.96078\tvalid-map:0.95986\n","[500]\ttrain-map:0.94873\tvalid-map:0.94557\n","[999]\ttrain-map:0.94971\tvalid-map:0.94559\n","[0]\ttrain-map:0.95866\tvalid-map:0.95804\n","[500]\ttrain-map:0.94864\tvalid-map:0.94599\n","[999]\ttrain-map:0.94964\tvalid-map:0.94596\n","[0]\ttrain-map:0.96273\tvalid-map:0.96277\n","[500]\ttrain-map:0.94853\tvalid-map:0.94625\n","[999]\ttrain-map:0.94958\tvalid-map:0.94624\n","[0]\ttrain-map:0.96110\tvalid-map:0.96169\n","[500]\ttrain-map:0.94838\tvalid-map:0.94689\n","[999]\ttrain-map:0.94937\tvalid-map:0.94686\n","orders Recall = 0.64924\n"]}]},{"cell_type":"markdown","source":["# inference"],"metadata":{"id":"qOu3QtnwDlgg"}},{"cell_type":"code","source":["def predict(test_candidates,TYPE):\n","    preds = np.zeros(len(test_candidates))\n","    test_candidates.reset_index(inplace=True)\n","    for fold in range(5):\n","        model = xgb.Booster()\n","        model.load_model(f'XGB_fold{fold}_{TYPE}.xgb')\n","        model.set_param({'predictor': 'gpu_predictor'})\n","        dtest = xgb.DMatrix(data=test_candidates[FEATURES].drop([\"user\"], axis=1))\n","        preds += model.predict(dtest)/5\n","    predictions = test_candidates[['user','item']].copy()\n","    predictions['pred'] = preds\n","    predictions = predictions.sort_values(['user','pred'], ascending=[True,False]).reset_index(drop=True)\n","    predictions['n'] = predictions.groupby('user').item.cumcount().astype('int8')\n","    predictions = predictions.loc[predictions.n<20]\n","    sub = predictions.groupby('user').item.apply(list)\n","    sub = sub.to_frame().reset_index()\n","    sub.item = sub.item.apply(lambda x: \" \".join(map(str,x)))\n","    sub.columns = ['session_type','labels']\n","    sub.session_type = sub.session_type.astype('str')+ f'_{TYPE}'\n","    return sub"],"metadata":{"id":"pAg9rnxjD0E8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## clicks"],"metadata":{"id":"AqM5ZFe7DpQ6"}},{"cell_type":"code","source":["%%time\n","test_candidates = merge_candidate(VER,'clicks','test')\n","clicks_pred_df = predict(test_candidates,'clicks')\n","del test_candidates\n","_ = gc.collect()"],"metadata":{"id":"soRBk_svFjwr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## carts"],"metadata":{"id":"9Zg10VZPDq-e"}},{"cell_type":"code","source":["%%time\n","test_candidates = merge_candidate(VER,'carts','test')\n","carts_pred_df = predict(test_candidates,'carts')\n","del test_candidates\n","_ = gc.collect()"],"metadata":{"id":"-rbhZVRkG8py"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## orders"],"metadata":{"id":"FLTRTzi8Dq5m"}},{"cell_type":"code","source":["%%time\n","test_candidates = merge_candidate(VER,'orders','test')\n","orders_pred_df = predict(test_candidates,'orders')\n","del test_candidates\n","_ = gc.collect()"],"metadata":{"id":"leINmPIdDk5o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# submission"],"metadata":{"id":"rcg9rVHYFVy4"}},{"cell_type":"code","source":["pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n","pred_df.columns = [\"session_type\", \"labels\"]\n","pred_df.to_csv(f\"xgb{VER}.csv\", index=False)\n","pred_df.to_csv(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/submission/xgb{VER}.csv', index=False)"],"metadata":{"id":"tkDJxfTEH4xu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install kaggle -q\n","import os\n","import json\n","f = open(\"/content/drive/MyDrive/Colab Notebooks/kaggle/kaggle.json\", 'r')\n","json_data = json.load(f)\n","os.environ['KAGGLE_USERNAME'] = json_data['username']\n","os.environ['KAGGLE_KEY'] = json_data['key']"],"metadata":{"id":"BorzGCTjFane"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kaggle competitions submit -c otto-recommender-system -f xgb1.csv -m \"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNvsNJWXFddN","executionInfo":{"status":"ok","timestamp":1674486177885,"user_tz":-540,"elapsed":21003,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"8c936d14-cb0e-4f76-e2bb-278d9e5e100d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 780M/780M [00:19<00:00, 43.0MB/s]\n","Successfully submitted to OTTO – Multi-Objective Recommender System"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DA6pkWvkIWkH"},"execution_count":null,"outputs":[]}]}