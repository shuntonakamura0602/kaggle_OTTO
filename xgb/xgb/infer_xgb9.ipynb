{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPiCYQ2PI/KX6v2lAaB72oT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Versions\n","\n","v1 pairwise\n","\n","v2 ndcg\n","\n","v3 map\n","\n","v4 pairwise,w_rank\n","\n","v5 pairwise,SVER2\n","\n","v6 ndcg,SVER2\n","\n","v7 map,SVER2\n","\n","v8 pairwise,SVER3\n","\n","v9 pairwise,SVER3,IVER2,UVER2"],"metadata":{"id":"bQVYIbrKP92d"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4cQfs0pkwFg","executionInfo":{"status":"ok","timestamp":1674959683756,"user_tz":-540,"elapsed":16705,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"c8dbc627-2db0-48d7-fdbc-ffaf8d651c8f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["VER = 9\n","SVER = 3\n","IVER = 2\n","UVER = 2\n","WVER = 1\n","FRAC = 0.5"],"metadata":{"id":"tccCIyvgCt5S","executionInfo":{"status":"ok","timestamp":1674959683757,"user_tz":-540,"elapsed":6,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1FcuFyf0kps","executionInfo":{"status":"ok","timestamp":1674959684804,"user_tz":-540,"elapsed":1052,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"66f96c6a-be6e-4d95-ba78-99a8752d62f3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jan 29 02:34:44 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import pandas as pd, numpy as np\n","import pickle, glob, gc\n","from collections import Counter\n","import itertools\n","# multiprocessing \n","import psutil\n","from multiprocessing import Pool\n","from sklearn.model_selection import GroupKFold\n","import psutil\n","import random\n","import os\n","N_CORES = psutil.cpu_count()     # Available CPU cores\n","print(f\"N Cores : {N_CORES}\")\n","from multiprocessing import Pool\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","\n","seed_everything(42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JewV2ba6m4rV","executionInfo":{"status":"ok","timestamp":1674959685904,"user_tz":-540,"elapsed":1103,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"a4837165-d6b4-428c-b844-d3ae5ef6e200"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["N Cores : 12\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","\n","def reduce_mem_usage(df):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.        \n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","\n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            df[col] = df[col].astype('category')\n","\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","\n","    return df"],"metadata":{"id":"0bgegXfbs7c7","executionInfo":{"status":"ok","timestamp":1674959685905,"user_tz":-540,"elapsed":6,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def merge_candidate(SVER,IVER,UVER,WVER,TYPE,MODE):\n","    candidates = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/candidate/suggest/{TYPE}/{MODE}_{TYPE}{SVER}.pqt')\n","    candidates['session'] = candidates.index\n","    candidates = candidates.set_index('session')\n","    item_features = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/candidate/item/{MODE}_item{IVER}.pqt')\n","    candidates = candidates.merge(item_features, left_on='item', right_index=True, how='left').fillna(-1)\n","    user_features = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/dataset/candidate/user/{MODE}_user{UVER}.pqt')\n","    candidates = candidates.merge(user_features, left_on='session', right_index=True, how='left').fillna(-1)\n","    candidates['user'] = candidates.index\n","    candidates = candidates.set_index('user')\n","    candidates = reduce_mem_usage(candidates)\n","    _ = gc.collect()\n","    return candidates"],"metadata":{"id":"pO7TL1NdpE2F","executionInfo":{"status":"ok","timestamp":1674959685905,"user_tz":-540,"elapsed":5,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pip install -q xgboost==1.6.2\n","import xgboost as xgb\n","from sklearn.model_selection import GroupKFold"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZE1qF8dEJXor","executionInfo":{"status":"ok","timestamp":1674959700963,"user_tz":-540,"elapsed":15062,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"efb0f27b-b2fe-4ca6-b29b-712b066bc754"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["# inference"],"metadata":{"id":"qOu3QtnwDlgg"}},{"cell_type":"code","source":["def predict(test_candidates,TYPE,FEATURES):\n","    preds = np.zeros(len(test_candidates))\n","    test_candidates.reset_index(inplace=True)\n","    for fold in range(5):\n","        model = xgb.Booster()\n","        model.load_model(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/weights/XGB_fold{fold}_{TYPE}_{VER}.xgb')\n","        model.set_param({'predictor': 'gpu_predictor'})\n","        dtest = xgb.DMatrix(data=test_candidates[FEATURES].drop([\"user\"], axis=1))\n","        preds += model.predict(dtest)/5\n","        del model,dtest\n","        _ = gc.collect()\n","    predictions = test_candidates[['user','item']].copy()\n","    predictions['pred'] = preds\n","    predictions = predictions.sort_values(['user','pred'], ascending=[True,False]).reset_index(drop=True)\n","    predictions['n'] = predictions.groupby('user').item.cumcount().astype('int8')\n","    predictions = predictions.loc[predictions.n<20]\n","    sub = predictions.groupby('user').item.apply(list)\n","    sub = sub.to_frame().reset_index()\n","    sub.item = sub.item.apply(lambda x: \" \".join(map(str,x)))\n","    sub.columns = ['session_type','labels']\n","    sub.session_type = sub.session_type.astype('str')+ f'_{TYPE}'\n","    del predictions\n","    _ = gc.collect()\n","    return sub"],"metadata":{"id":"pAg9rnxjD0E8","executionInfo":{"status":"ok","timestamp":1674959700964,"user_tz":-540,"elapsed":6,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## clicks"],"metadata":{"id":"AqM5ZFe7DpQ6"}},{"cell_type":"code","source":["%%time\n","test_candidates = merge_candidate(SVER,IVER,UVER,WVER,'clicks','test')\n","FEATURES = list(test_candidates.columns)\n","FEATURES = FEATURES + ['user']\n","FEATURES.remove('item')\n","clicks_pred_df = predict(test_candidates,'clicks',FEATURES)\n","del test_candidates\n","_ = gc.collect()"],"metadata":{"id":"soRBk_svFjwr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674959989677,"user_tz":-540,"elapsed":288718,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"eb2162c4-730f-4fca-c5e7-957304a96403"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory usage of dataframe is 11479.36 MB\n","Memory usage after optimization is: 5484.58 MB\n","Decreased by 52.2%\n","CPU times: user 13min 43s, sys: 29.2 s, total: 14min 13s\n","Wall time: 4min 49s\n"]}]},{"cell_type":"markdown","source":["## carts"],"metadata":{"id":"9Zg10VZPDq-e"}},{"cell_type":"code","source":["%%time\n","test_candidates = merge_candidate(SVER,IVER,UVER,WVER,'carts','test')\n","FEATURES = list(test_candidates.columns)\n","FEATURES = FEATURES + ['user']\n","FEATURES.remove('item')\n","carts_pred_df = predict(test_candidates,'carts',FEATURES)\n","del test_candidates\n","_ = gc.collect()"],"metadata":{"id":"-rbhZVRkG8py","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674960238819,"user_tz":-540,"elapsed":249147,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"f274d834-b972-40c6-85db-6c1170499547"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory usage of dataframe is 11479.36 MB\n","Memory usage after optimization is: 5484.58 MB\n","Decreased by 52.2%\n","CPU times: user 11min 16s, sys: 11.1 s, total: 11min 27s\n","Wall time: 4min 9s\n"]}]},{"cell_type":"markdown","source":["## orders"],"metadata":{"id":"FLTRTzi8Dq5m"}},{"cell_type":"code","source":["%%time\n","test_candidates = merge_candidate(SVER,IVER,UVER,WVER,'orders','test')\n","FEATURES = list(test_candidates.columns)\n","FEATURES = FEATURES + ['user']\n","FEATURES.remove('item')\n","orders_pred_df = predict(test_candidates,'orders',FEATURES)\n","del test_candidates\n","_ = gc.collect()"],"metadata":{"id":"leINmPIdDk5o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674960470214,"user_tz":-540,"elapsed":231413,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"641e8d61-5480-4214-d94d-c87e2ffe263e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory usage of dataframe is 11479.36 MB\n","Memory usage after optimization is: 5484.58 MB\n","Decreased by 52.2%\n","CPU times: user 10min 7s, sys: 4.01 s, total: 10min 11s\n","Wall time: 3min 51s\n"]}]},{"cell_type":"markdown","source":["# submission"],"metadata":{"id":"rcg9rVHYFVy4"}},{"cell_type":"code","source":["pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n","pred_df.columns = [\"session_type\", \"labels\"]\n","pred_df.to_csv(f\"xgb{VER}.csv\", index=False)\n","pred_df.to_csv(f'/content/drive/MyDrive/Colab Notebooks/kaggle/OTTO/submission/xgb{VER}.csv', index=False)"],"metadata":{"id":"tkDJxfTEH4xu","executionInfo":{"status":"ok","timestamp":1674960510519,"user_tz":-540,"elapsed":40309,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!pip install kaggle -q\n","import os\n","import json\n","f = open(\"/content/drive/MyDrive/Colab Notebooks/kaggle/kaggle.json\", 'r')\n","json_data = json.load(f)\n","os.environ['KAGGLE_USERNAME'] = json_data['username']\n","os.environ['KAGGLE_KEY'] = json_data['key']"],"metadata":{"id":"BorzGCTjFane","executionInfo":{"status":"ok","timestamp":1674960515714,"user_tz":-540,"elapsed":5212,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!kaggle competitions submit -c otto-recommender-system -f xgb9.csv -m \"\""],"metadata":{"id":"WNvsNJWXFddN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674960533260,"user_tz":-540,"elapsed":17303,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}},"outputId":"6920c400-1d02-45b6-ac6e-d300fc363e13"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 778M/778M [00:15<00:00, 54.3MB/s]\n","Successfully submitted to OTTO – Multi-Objective Recommender System"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TaSbfFQf0OHO","executionInfo":{"status":"aborted","timestamp":1674959543391,"user_tz":-540,"elapsed":19,"user":{"displayName":"ナカムラシュント","userId":"10300597884041758713"}}},"execution_count":null,"outputs":[]}]}